{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Logistic Regression Model Example\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "### Regression\n",
    "For this project, we will use Supervised Learning and the Regression model to predict poverty level. Poverty level is a continuous variable which can be any numerical value within a certain range. The regression model's algorithms would attempt to learn patterns that exist among the selected economic factors. If presented with the data of a state, the model would make a prediction of the proverty level based on previously learned patterns from the dataset.\n",
    "\n",
    "### Classification\n",
    "Classification is used to predict discrete outcomes. The target variable only has two possible values.\n",
    "\n",
    "### Dataset for Regression and Classification\n",
    "Dataset is divided into features and target. \n",
    "* Features are the variables used to make a prediction\n",
    "* Target is the predicted outcome.\n",
    "\n",
    "### Basic procedures for implementing a supervised learning model:\n",
    "1. Create a model with LogisticRegression().\n",
    "2. Train the model with model.fit().\n",
    "3. Make predictions with model.predict().\n",
    "4. Validate the model with accuracy_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database dependencies\n",
    "from sqlalchemy import inspect, create_engine\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "import config as creds\n",
    "\n",
    "# Import Pandas and matplotlib dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import scikit packages\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.datasets as datasets\n",
    "# For splitting of data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Metrics for Evaluation of model Accuracy and F1-score\n",
    "from sklearn.metrics  import f1_score,accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f'postgresql://{creds.PGUSER}:{creds.PGPASSWORD}@{creds.PGHOST}:5432/{creds.PGDATABASE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(bind=engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ave_wage_indexing',\n",
       " 'welfare_education',\n",
       " 'cpi_inflation_rate',\n",
       " 'crime_rate',\n",
       " 'economic_features_full',\n",
       " 'economic_features',\n",
       " 'divorce_rate',\n",
       " 'homeownership_rate',\n",
       " 'min_wage_effective',\n",
       " 'poverty_rates',\n",
       " 'unemployment_rate']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tables in database\n",
    "inspect(engine).get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'state',\n",
       " 'population_million',\n",
       " 'education_million',\n",
       " 'welfare_million',\n",
       " 'crime_rate',\n",
       " 'unemployment_rate',\n",
       " 'divorce_rate_per_1000_people',\n",
       " 'homeownership_rate',\n",
       " 'minimum_wage_effective',\n",
       " 'cpi_average',\n",
       " 'avg_wage_index',\n",
       " 'poverty_rate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List columns in a specific table ('min_wage')\n",
    "[column['name'] for column in inspect(engine).get_columns('economic_features')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* Visualize dataset\n",
    "* Reshape data format if needed\n",
    "* Use standardizing functions if necessary: MinMax and Standard functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Poverty Level\"]\n",
    "X = df.drop(columns=\"Poverty Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.YearsExperience, df.Salary)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "# xlabel = independent variable\n",
    "# ylabel = target variable that we want to predict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data format if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use reshape() to format data to meet the Scikit-learn library requirements\n",
    "# Reshape dataset format \n",
    "X = df.X_column_name.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To examine the first 5 entries in X\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To examine the shape of X\n",
    "X.shape\n",
    "\n",
    "# 30 rows and 1 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale standardization - MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax shrinks the range of each figure \n",
    "import sklearn.preprocessing as preprocessing\n",
    " \n",
    "minmax = preprocessing.MinMaxScaler()\n",
    "# X is a matrix with float type\n",
    "minmax.fit(X)\n",
    "X_minmax = minmax.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale standardization - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "std = preprocessing.StandardScaler()\n",
    "# X is a matrix\n",
    "std.fit(X)\n",
    "X_std = std.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign target variable\n",
    "y = df.Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train & Test set\n",
    "Conventional split is: 75% for training, 25% for testing set\n",
    "\n",
    "* Model uses the training dataset to learn from it\n",
    "* Model uses the testing dataset to assess its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "    y, random_state=1, stratify=y)\n",
    "\n",
    "# X = input\n",
    "# y = output or what we wish to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating instance of logistic regression model\n",
    "* import LogisticRegression from the Scikit-learn library, and then instantiate the model.\n",
    "* **solver argument** is set to 'lbfgs', which is the default setting, \n",
    "* **random_state** is specified to reproduce the same results as you run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "   intercept_scaling=1, max_iter=100, multi_class='warn', penalty='12',\n",
    "   random_state=1, solver='lbfgs' tol=0.0001, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (fitting) the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data into the model\n",
    "# By convention, X is capitalized and y is lowercase\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and evaluating the model\n",
    "Generate predictions and evaluate performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions using predict() methodd and put results into a Pandas DataFrame\n",
    "# The model creates predicted y values based on X values\n",
    "predictions = classifier.predict(X_test)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n",
    "\n",
    "\n",
    "# Validate the model, or evaluate its performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data point to show up as a red dot on the new plot\n",
    "import numpy as np\n",
    "new_data = np.array([[-2, 6]])\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.scatter(new_data[0, 0], new_data[0, 1], c=\"r\", marker=\"o\", s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(new_data)\n",
    "print(\"Classes are either 0 (purple) or 1 (yellow)\")\n",
    "print(f\"The new point was classified as: {predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
